{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Uncertainty Estimation using Deep Ensemble (Regression)\n",
    "\n",
    "This algorithm is implementation of paper [Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles](https://arxiv.org/abs/1612.01474). In this jupyter notebook, I will implement regression part of this paper using [Concrete Compressive Strength Dataset](https://archive.ics.uci.edu/ml/datasets/Concrete+Compressive+Strength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scipy.io\n",
    "import cv2\n",
    "import random\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters of training\n",
    "Learning_rate = 0.00025\n",
    "epsilon = 1e-8\n",
    "\n",
    "num_iter = 5000\n",
    "batch_size = 128\n",
    "\n",
    "test_ratio = 0.1\n",
    "gpu_fraction = 0.5\n",
    "\n",
    "# Ensemble networks\n",
    "networks = ['network1', 'network2', 'network3', 'network4', 'network5']\n",
    "\n",
    "# Import Excel File\n",
    "data = pandas.read_excel('Concrete_Data.xls')\n",
    "column_names = data.columns\n",
    "\n",
    "num_rows = len(data)\n",
    "num_columns = len(column_names) \n",
    "num_data = num_columns - 1\n",
    "\n",
    "# Dense [input size, output size]\n",
    "dense1 = [num_data, 100]\n",
    "dense2 = [100, 100]\n",
    "dense_mu  = [100, 1]\n",
    "dense_sig = [100, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Concrete Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (927, 8)\n",
      "Test data shape: (103, 8)\n"
     ]
    }
   ],
   "source": [
    "data_x = np.zeros([num_rows, num_columns - 1])\n",
    "data_y = np.zeros([num_rows, 1])\n",
    "\n",
    "for i in range(num_rows):\n",
    "    for j in range(num_columns - 1):\n",
    "        data_x[i, j] = data[column_names[j]][i]\n",
    "    data_y[i,0] = data[column_names[-1]][i]\n",
    "\n",
    "num_train_data = int(num_rows * (1 - test_ratio))\n",
    "num_test_data  = num_rows - num_train_data\n",
    "\n",
    "train_x = data_x[:num_train_data, :]\n",
    "train_y = data_y[:num_train_data, :]\n",
    "test_x  = data_x[num_train_data:, :]\n",
    "test_y  = data_y[num_train_data:, :]\n",
    "\n",
    "print(\"Train data shape: \" + str(train_x.shape))\n",
    "print(\"Test data shape: \" + str(test_x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "def weight_variable(name, shape):\n",
    "    return tf.get_variable(name, shape = shape, initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "def bias_variable(name, shape):\n",
    "    return tf.get_variable(name, shape = shape, initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "# Get networks\n",
    "def get_network(network_name):\n",
    "    input_x = tf.placeholder(tf.float32, shape = [None, num_data])\n",
    "    \n",
    "    with tf.variable_scope(network_name):\n",
    "        # Densely connect layer variables\n",
    "        w_fc1 = weight_variable(network_name + '_w_fc1', dense1)\n",
    "        b_fc1 = bias_variable(network_name + '_b_fc1', [dense1[1]])\n",
    "        \n",
    "        w_fc2 = weight_variable(network_name + '_w_fc2', dense2)\n",
    "        b_fc2 = bias_variable(network_name + '_b_fc2', [dense2[1]])\n",
    "        \n",
    "        w_fc_mu = weight_variable(network_name + '_w_fc_mu', dense_mu)\n",
    "        b_fc_mu = bias_variable(network_name + '_b_fc_mu', [dense_mu[1]])\n",
    "\n",
    "        w_fc_sig = weight_variable(network_name + '_w_fc_sig', dense_sig)\n",
    "        b_fc_sig = bias_variable(network_name + '_b_fc_sig', [dense_sig[1]])\n",
    "\n",
    "    # Network\n",
    "    fc1 = tf.nn.relu(tf.matmul(input_x, w_fc1) + b_fc1)\n",
    "    fc2 = tf.nn.relu(tf.matmul(fc1, w_fc2) + b_fc2)\n",
    "    output_mu  = tf.matmul(fc2, w_fc_mu) + b_fc_mu\n",
    "    output_sig = tf.matmul(fc2, w_fc_sig) + b_fc_sig\n",
    "    \n",
    "    y = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "    \n",
    "    # Negative Log Likelihood(NLL) \n",
    "#     loss = tf.reduce_mean(tf.div(tf.log(tf.square(output_sig)), 2) + tf.div(tf.square(y - output_mu), 2 * tf.square(output_sig) + 1e-10)) \n",
    "#     loss = tf.reduce_mean(tf.div(tf.log(tf.square(output_sig)), 2) + tf.div(tf.square(y - output_mu), 2 * tf.square(output_sig) + 1e-10)) \n",
    "\n",
    "    # Get trainable variables\n",
    "    train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, network_name) \n",
    "    \n",
    "    train_opt = tf.train.AdamOptimizer(Learning_rate).minimize(loss, var_list = train_vars)\n",
    "    \n",
    "    return input_x, y, output_mu, output_sig, loss, train_opt, train_vars\n",
    "\n",
    "\n",
    "# Make batch data \n",
    "def making_batch(data_size, sample_size, data_x, data_y):\n",
    "    \n",
    "    # Making batches(testing)\n",
    "    batch_idx = np.random.choice(data_size, sample_size)\n",
    "    \n",
    "    batch_x = np.zeros([sample_size, num_data])\n",
    "    batch_y = np.zeros([sample_size, 1])\n",
    "        \n",
    "    for i in range(batch_idx.shape[0]):\n",
    "        batch_x[i,:] = data_x[batch_idx[i], :]\n",
    "        batch_y[i,:] = data_y[batch_idx[i], :] \n",
    "        \n",
    "    return batch_x, batch_y   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Ensemble Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_list = []\n",
    "y_list = []\n",
    "output_mu_list = []\n",
    "output_sig_list = []\n",
    "loss_list = []\n",
    "train_list = []\n",
    "train_var_list = []\n",
    "\n",
    "# Train each ensemble network\n",
    "for i in range(len(networks)):\n",
    "    x_input, y, output_mu, output_sig, loss, train_opt, train_vars = get_network(networks[i])\n",
    "\n",
    "    x_list.append(x_input)\n",
    "    y_list.append(y)\n",
    "    output_mu_list.append(output_mu)\n",
    "    output_sig_list.append(output_sig)\n",
    "    loss_list.append(loss)\n",
    "    train_list.append(train_opt)\n",
    "    train_var_list.append(train_vars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = gpu_fraction\n",
    "\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- Iteration: 100 -------------------------\n",
      "Average Loss(NLL): [ 12334.66612      6492.86813812  36851.87665497   4655.21759399\n",
      "   1996.95144501]\n",
      "104.28578186\n",
      "20374.6777614\n",
      "[ 13.20208645]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 200 -------------------------\n",
      "Average Loss(NLL): [  5018.46291931   2162.81270874  11979.14311401  10925.32436523\n",
      "   2495.0925473 ]\n",
      "101.405927777\n",
      "22064.995248\n",
      "[ 18.28766142]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 300 -------------------------\n",
      "Average Loss(NLL): [  1737.5201123    1184.14719727   2421.89954468   8979.86837402\n",
      "  11476.91382141]\n",
      "118.967609406\n",
      "30226.590465\n",
      "[ 38.46103971]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 400 -------------------------\n",
      "Average Loss(NLL): [  1667.2850415    1003.1269281     269.34195816   3881.36210693\n",
      "  43788.59782257]\n",
      "128.341553283\n",
      "31628.6333227\n",
      "[ 25.5595648]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 500 -------------------------\n",
      "Average Loss(NLL): [  1584.78148804    932.04880005    277.27942261   2918.89434326\n",
      "  46604.51164063]\n",
      "122.749629211\n",
      "35240.8780989\n",
      "[ 33.39959639]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 600 -------------------------\n",
      "Average Loss(NLL): [ 12940.20797729    884.17023682    273.98135208   1701.97033203\n",
      "  44475.51351563]\n",
      "118.221658611\n",
      "28460.4860941\n",
      "[ 24.5798194]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 700 -------------------------\n",
      "Average Loss(NLL): [ 12701.8015918     840.27179993    270.87469696   1629.00875977\n",
      "  31921.3094043 ]\n",
      "116.753078461\n",
      "22031.0509676\n",
      "[ 33.05347944]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 800 -------------------------\n",
      "Average Loss(NLL): [ 11064.52837402    805.60012329    273.33789688   1259.34641724\n",
      "   5741.3122937 ]\n",
      "116.977827454\n",
      "17625.932918\n",
      "[ 53.52471136]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 900 -------------------------\n",
      "Average Loss(NLL): [  2308.76512939    787.13249939    266.53504532   1089.19801025\n",
      "  16450.31137573]\n",
      "118.027444458\n",
      "21307.5423464\n",
      "[ 43.79827342]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 1000 -------------------------\n",
      "Average Loss(NLL): [  3722.4311853     743.12241516    269.19706161    968.95361816\n",
      "  12258.67555664]\n",
      "131.456177521\n",
      "24362.2567747\n",
      "[ 23.74417449]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 1100 -------------------------\n",
      "Average Loss(NLL): [  3180.34731934    733.81291382    254.6288829     874.11346497\n",
      "  12196.68746094]\n",
      "126.936842728\n",
      "20192.9140407\n",
      "[ 36.80491836]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 1200 -------------------------\n",
      "Average Loss(NLL): [  3114.91283447  21842.96708588    246.47115036    755.03076843\n",
      "  12225.25369141]\n",
      "103.219057798\n",
      "31296.8469909\n",
      "[ 32.24541357]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 1300 -------------------------\n",
      "Average Loss(NLL): [  3047.71722656   8285.69466797  33475.15779495    652.78270996\n",
      "  12179.78324219]\n",
      "95.4376626968\n",
      "32717.1427914\n",
      "[ 33.798803]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 1400 -------------------------\n",
      "Average Loss(NLL): [  3001.38921875   5051.89896973  28824.37484375    536.11569885\n",
      "  12226.41512695]\n",
      "103.892904758\n",
      "29261.5616791\n",
      "[ 9.73815902]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 1500 -------------------------\n",
      "Average Loss(NLL): [  2964.78305908   5194.11715332  28832.70447266    415.81762756\n",
      "  12185.80686523]\n",
      "90.4760138512\n",
      "27591.4542708\n",
      "[ 21.91154728]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 1600 -------------------------\n",
      "Average Loss(NLL): [  2912.83135254   5172.87126953  28503.25775391    349.86149658\n",
      "  12313.89516602]\n",
      "76.3576183319\n",
      "23664.7262098\n",
      "[ 35.22532884]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 1700 -------------------------\n",
      "Average Loss(NLL): [  2866.18419922   5137.31038086  28404.3578125     302.11776031\n",
      "  12006.76858398]\n",
      "69.562059021\n",
      "25886.9850477\n",
      "[ 44.6118551]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 1800 -------------------------\n",
      "Average Loss(NLL): [  2854.4119165    5129.50791016  28354.70765625    248.4302948\n",
      "   5973.74574585]\n",
      "70.2255729675\n",
      "24542.7205373\n",
      "[ 36.3498642]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 1900 -------------------------\n",
      "Average Loss(NLL): [  2819.41778076   5064.47550293  28171.38613281  32810.2837674\n",
      "   3560.76348877]\n",
      "65.880045414\n",
      "60250.4783674\n",
      "[ 33.71882378]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 2000 -------------------------\n",
      "Average Loss(NLL): [  2802.35280273   5092.02890137  18349.84520264  89515.20820313\n",
      "   2710.40606323]\n",
      "67.0931298256\n",
      "38834.822176\n",
      "[ 37.17103011]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 2100 -------------------------\n",
      "Average Loss(NLL): [  2755.35022217   5064.12579102   1445.95284424  40637.17131836\n",
      "   2296.05070801]\n",
      "54.6884822845\n",
      "26611.9199978\n",
      "[ 32.96384756]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 2200 -------------------------\n",
      "Average Loss(NLL): [ 2714.98598389  5023.72432617  2179.24121094  6286.33830566  2152.69376221]\n",
      "62.5871765137\n",
      "12401.0208293\n",
      "[ 31.1787942]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 2300 -------------------------\n",
      "Average Loss(NLL): [   2710.75596924    4977.00444824    2844.73109619  101591.13712769\n",
      "    1985.47774414]\n",
      "34.1955253601\n",
      "41102.5491267\n",
      "[ 30.88163004]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 2400 -------------------------\n",
      "Average Loss(NLL): [   2651.00377441    4962.57419922    2901.33851807  116484.27179687\n",
      "    1854.32602051]\n",
      "43.9806003571\n",
      "64169.0636104\n",
      "[ 39.45595358]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 2500 -------------------------\n",
      "Average Loss(NLL): [   2621.46066895    4892.16951172    2847.70606934  108966.17398437\n",
      "    1723.4754895 ]\n",
      "47.8434139252\n",
      "44885.8195462\n",
      "[ 10.53588276]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 2600 -------------------------\n",
      "Average Loss(NLL): [  2577.02414551   4846.65237793   2793.67609375  91399.15796875\n",
      "   1636.25096313]\n",
      "42.5717754364\n",
      "49496.8251141\n",
      "[ 19.0095428]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 2700 -------------------------\n",
      "Average Loss(NLL): [  2537.70567871   4829.17100098   2736.54189209  27503.45508301\n",
      "   1518.56047607]\n",
      "33.6577301025\n",
      "12243.4221784\n",
      "[ 40.8686899]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 2800 -------------------------\n",
      "Average Loss(NLL): [   2477.98041992    4816.54745605    2680.98575195  102425.33213867\n",
      "    1418.55320679]\n",
      "39.3174751282\n",
      "30149.8792061\n",
      "[ 23.52423164]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 2900 -------------------------\n",
      "Average Loss(NLL): [  2442.0992334    4740.39169922   2638.29580322  23663.37195801\n",
      "   1346.81058899]\n",
      "24.9183921814\n",
      "13297.0022247\n",
      "[ 33.05347944]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 3000 -------------------------\n",
      "Average Loss(NLL): [  2400.75156494   4705.49039063   2566.91671143  27631.41835937\n",
      "   1248.92326721]\n",
      "45.1876279831\n",
      "14591.2245835\n",
      "[ 38.6306508]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 3100 -------------------------\n",
      "Average Loss(NLL): [  2305.43430664   4677.07189453   2522.19738037  24441.23519531\n",
      "   1189.69511597]\n",
      "37.1455595016\n",
      "12141.38904\n",
      "[ 24.5798194]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 3200 -------------------------\n",
      "Average Loss(NLL): [  2238.72958862   4592.54898438   2467.71705078  22237.96566406\n",
      "   1111.63252625]\n",
      "34.3463321686\n",
      "17911.1799982\n",
      "[ 26.23318285]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 3300 -------------------------\n",
      "Average Loss(NLL): [   2189.4730481     4584.17296875    2393.04048828  108221.05883789\n",
      "    1034.32187439]\n",
      "53.0383560181\n",
      "95676.9368888\n",
      "[ 27.68108245]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 3400 -------------------------\n",
      "Average Loss(NLL): [   2464.58424438    4510.32071289    2342.35557373  264133.56453125\n",
      "     996.45549927]\n",
      "54.7157243252\n",
      "69910.9821025\n",
      "[ 24.5798194]\n",
      "\n",
      "\n",
      "------------------------- Iteration: 3500 -------------------------\n",
      "Average Loss(NLL): [   2990.23902344    4443.34630127    2257.86909424  261162.1046875\n",
      "     949.50637329]\n",
      "60.887842679\n",
      "102950.214052\n",
      "[ 13.29378676]\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-bbea3b24785f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[1;31m# Testing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         loss_test, mu_test, sig_test = sess.run([loss_list[i], output_mu_list[i], output_sig_list[i]], \n\u001b[0;32m---> 28\u001b[0;31m                                          feed_dict = {x_list[i]: batch_x_test, y_list[i]: batch_y_test})\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0msig_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Q\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Q\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Q\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Q\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Q\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set parameters for printing and testing\n",
    "num_print = 100\n",
    "test_size = 10\n",
    "\n",
    "train_data_num = train_x.shape[0]\n",
    "test_data_num  = test_x.shape[0]\n",
    "\n",
    "loss_train = np.zeros([len(networks)])\n",
    "out_mu     = np.zeros([test_size, len(networks)])\n",
    "out_sig    = np.zeros([test_size, len(networks)])\n",
    "\n",
    "for iter in range(num_iter):\n",
    "    # Making batches(testing)\n",
    "    batch_x_test, batch_y_test = making_batch(test_data_num, test_size, test_x, test_y)\n",
    "        \n",
    "    for i in range(len(networks)):\n",
    "        # Making batches(training)\n",
    "        batch_x, batch_y = making_batch(train_data_num, batch_size, train_x, train_y)\n",
    "       \n",
    "        # Training\n",
    "        _, loss, mu, sig = sess.run([train_list[i], loss_list[i], output_mu_list[i], output_sig_list[i]], \n",
    "                                 feed_dict = {x_list[i]: batch_x, y_list[i]: batch_y})\n",
    "        \n",
    "        sig = np.square(sig)\n",
    "        \n",
    "        # Testing\n",
    "        loss_test, mu_test, sig_test = sess.run([loss_list[i], output_mu_list[i], output_sig_list[i]], \n",
    "                                         feed_dict = {x_list[i]: batch_x_test, y_list[i]: batch_y_test})\n",
    "        \n",
    "        sig_test = np.square(sig_test)\n",
    "        \n",
    "        loss_train[i] += loss\n",
    "        out_mu[:, i] = np.reshape(mu_test, (test_size))\n",
    "        out_sig[:, i] = np.reshape(sig_test, (test_size))\n",
    "        \n",
    "    # Get final test result\n",
    "    out_mu_final = np.mean(out_mu, axis = 1)\n",
    "    out_sig_final = np.mean(out_sig + np.square(out_mu), axis = 1) - np.square(out_mu_final)\n",
    "    \n",
    "    if iter % num_print == 0 and iter != 0:\n",
    "        print(('-------------------------') + ' Iteration: ' + str(iter) + ' -------------------------')\n",
    "        print('Average Loss(NLL): ' + str(loss_train / num_print))\n",
    "        print(out_mu_final[0])\n",
    "        print(out_sig_final[0])\n",
    "        print(batch_y_test[0])\n",
    "#         print('Testing Accuracy: ' + str(acc_check_test / num_print))\n",
    "#         print('Final Testing Accuracy: ' + str(acc_check_test_final / num_print))\n",
    "        print('\\n')\n",
    "        \n",
    "        loss_train = np.zeros(len(networks))\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
